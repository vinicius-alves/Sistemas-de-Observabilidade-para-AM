{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Core.DTO import *\n",
    "from Core.Relations import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import re, json\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conex√£o com banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Configura√ß√£o do banco (pode ser reutilizada para qualquer ModelDTOo)\n",
    "mongo_url = \"mongodb://localhost:27017/\"\n",
    "db_manager = DatabaseManager('mysql+pymysql://root:000000000@localhost/mydb', mongo_url = mongo_url)\n",
    "session = db_manager.get_session()\n",
    "dataset_repo = DatasetRepository(session)\n",
    "conversor = ConverterDTO(session=session)\n",
    "mongo_db = db_manager.get_mongo_db()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'LoanDefaultPrediction'\n",
    "target_feature_name = 'default'\n",
    "name_space= project_name\n",
    "\n",
    "\n",
    "def process_raw_loan_data():\n",
    "\n",
    "    columns = ['id', 'loan_amnt', 'term', 'int_rate', 'installment', 'emp_length',\n",
    "       'home_ownership', 'annual_inc', 'verification_status', 'issue_d',\n",
    "       'loan_status', 'purpose', 'addr_state', 'dti']\n",
    "\n",
    "    df = pd.read_csv('data//Loan.csv', usecols = columns )\n",
    "    \n",
    "    df['term'] = df['term'].str.strip().str.split(' ').map(lambda x: x[0]).astype('int')\n",
    "    df['timestamp'] = pd.to_datetime(df['issue_d'], format=\"%b-%y\")\n",
    "\n",
    "    dict_emp = {'10+ years': 10,\n",
    "    '< 1 year': 0,\n",
    "    '1 year': 1,\n",
    "    '3 years': 3,\n",
    "    '8 years': 8,\n",
    "    '9 years': 9,\n",
    "    '4 years': 4,\n",
    "    '5 years': 5,\n",
    "    '6 years': 6,\n",
    "    '2 years': 2,\n",
    "    '7 years': 7}\n",
    "\n",
    "    ix = df['emp_length'].notnull()\n",
    "    df.loc[ix,'emp_length'] = df.loc[ix,'emp_length'].map(lambda x : dict_emp[x])\n",
    "    df['emp_length'] = df['emp_length'].astype('float')\n",
    "    df['int_rate'] = df['int_rate'].str.replace('%','', regex=False).astype('float')\n",
    "\n",
    "    df = df[df['loan_status'] != 'Current'].reset_index(drop=True)\n",
    "    df['default'] = (df['loan_status'] == 'Charged Off').astype('int')\n",
    "    df.drop(columns = ['issue_d','loan_status'], inplace=True)\n",
    "    df.rename(columns={'id':'idEntity'}, inplace=True)\n",
    "    df['idEntity'] = df['idEntity'].astype('string')\n",
    "    df = df[df['timestamp']<'2011-02-01'].reset_index(drop=True)\n",
    "\n",
    "    df_melt = df.melt(id_vars = ['timestamp','idEntity'], value_vars = df.drop(columns = 'timestamp').columns)\n",
    "    df_melt['type'] = df_melt['value'].map(lambda x : type(x).__name__)\n",
    "    df_melt.rename(columns ={'variable':'name'}, inplace=True)\n",
    "\n",
    "    return df_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = Dataset(name = project_name)\n",
    "item_exists, dataset_dto = conversor.get_if_exists(dataset)\n",
    "\n",
    "if not(item_exists):\n",
    "    df = process_raw_loan_data()\n",
    "\n",
    "    dataset_dto = DatasetDTO(name = project_name ) \n",
    "    lst_features= df['name'].drop_duplicates().to_list()\n",
    "    dataset_dto.process_feature_list(lst_features= lst_features, name_space=name_space)\n",
    "    dataset_repo.save(dataset_dto)\n",
    "    item_exists, dataset_dto = conversor.get_if_exists(dataset)\n",
    "    dataset_dto.save_data_mongo(mongo_db ,df = df)\n",
    "\n",
    "dataset_dto.load_data_from_mongo(mongo_db)\n",
    "dataset = dataset_dto.dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetFeature = Feature(name = target_feature_name, nameSpace = FeatureNameSpace(name = name_space))\n",
    "project = Project(name  = project_name, projectType = ProjectType(name = 'Classification'), targetFeature = targetFeature)\n",
    "\n",
    "item_exists,project_dto = conversor.get_if_exists(project)\n",
    "\n",
    "if not(item_exists):\n",
    "\ttargetFeature = dataset_dto.get_feature_by_name(name = target_feature_name)\n",
    "\tproject_dto =ProjectDTO(name  = project_name, projectType = ProjectTypeDTO(name = 'Classification'), targetFeature = targetFeature)\n",
    "\tProjectRepository(session=session).save(project_dto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8943e3c818cf417e89baa0dce96f5459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|=================== | 453/478 [00:12<00:00]       c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\Lift10MeasureProcedure.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  top_k_rate = positives_top_k / cutoff\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\Lift10MeasureProcedure.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  top_k_rate = positives_top_k / cutoff\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\Lift10MeasureProcedure.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  top_k_rate = positives_top_k / cutoff\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\Lift10MeasureProcedure.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  top_k_rate = positives_top_k / cutoff\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\Lift10MeasureProcedure.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  top_k_rate = positives_top_k / cutoff\n",
      " 99%|===================| 1183/1196 [00:26<00:00]        c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      " 99%|===================| 1453/1474 [00:36<00:00]        c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "100%|===================| 2253/2264 [01:15<00:00]        "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m run = Run(project = project,dataset = dataset, task = task,  model = model)\n\u001b[32m     25\u001b[39m run.execute( task_parameters={\u001b[33m'\u001b[39m\u001b[33mstart_date\u001b[39m\u001b[33m'\u001b[39m:data_inicio,\u001b[33m'\u001b[39m\u001b[33mend_date\u001b[39m\u001b[33m'\u001b[39m:data_fim, \u001b[33m'\u001b[39m\u001b[33mslices\u001b[39m\u001b[33m'\u001b[39m :slices})\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m run_dto = \u001b[43mconversor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverter_object_to_dto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m run_repo = RunRepository(session=session)\n\u001b[32m     29\u001b[39m run_repo.save(run_dto)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\DTO\\ConverterDTO.py:57\u001b[39m, in \u001b[36mConverterDTO.converter_object_to_dto\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m     55\u001b[39m         \u001b[38;5;28msetattr\u001b[39m(obj_dto_prototype, key, [])\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m value:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m         item_dto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconverter_object_to_dto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m         \u001b[38;5;28mgetattr\u001b[39m(obj_dto_prototype, key).append(item_dto)           \n\u001b[32m     59\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\DTO\\ConverterDTO.py:57\u001b[39m, in \u001b[36mConverterDTO.converter_object_to_dto\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m     55\u001b[39m         \u001b[38;5;28msetattr\u001b[39m(obj_dto_prototype, key, [])\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m value:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m         item_dto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconverter_object_to_dto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m         \u001b[38;5;28mgetattr\u001b[39m(obj_dto_prototype, key).append(item_dto)           \n\u001b[32m     59\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\DTO\\ConverterDTO.py:51\u001b[39m, in \u001b[36mConverterDTO.converter_object_to_dto\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m     49\u001b[39m value_dto = value\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value.\u001b[34m__class__\u001b[39m.\u001b[34m__module__\u001b[39m.startswith(\u001b[33m'\u001b[39m\u001b[33mCore.Relations\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     value_dto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconverter_object_to_dto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(value) == \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m(\u001b[38;5;28mhasattr\u001b[39m(obj_dto_prototype, key)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\DTO\\ConverterDTO.py:32\u001b[39m, in \u001b[36mConverterDTO.converter_object_to_dto\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m(obj.\u001b[34m__class__\u001b[39m.\u001b[34m__module__\u001b[39m.startswith(\u001b[33m'\u001b[39m\u001b[33mCore.Relations\u001b[39m\u001b[33m'\u001b[39m)):\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m item_exists, obj_dto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_if_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m item_exists:\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj_dto\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\DTO\\ConverterDTO.py:92\u001b[39m, in \u001b[36mConverterDTO.get_if_exists\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m all_items_none:\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, obj_dto_prototype\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m existing_item = \u001b[43mrepo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter_by\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_search\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m existing_item:\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m, existing_item\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sqlalchemy\\orm\\query.py:2759\u001b[39m, in \u001b[36mQuery.first\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2757\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter().first()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   2758\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2759\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.first()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sqlalchemy\\orm\\query.py:2857\u001b[39m, in \u001b[36mQuery._iter\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2854\u001b[39m params = \u001b[38;5;28mself\u001b[39m._params\n\u001b[32m   2856\u001b[39m statement = \u001b[38;5;28mself\u001b[39m._statement_20()\n\u001b[32m-> \u001b[39m\u001b[32m2857\u001b[39m result: Union[ScalarResult[_T], Result[_T]] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2858\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2859\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2860\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_sa_orm_load_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_options\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2861\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2863\u001b[39m \u001b[38;5;66;03m# legacy: automatically set scalars, unique\u001b[39;00m\n\u001b[32m   2864\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result._attributes.get(\u001b[33m\"\u001b[39m\u001b[33mis_single_entity\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:2365\u001b[39m, in \u001b[36mSession.execute\u001b[39m\u001b[34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event)\u001b[39m\n\u001b[32m   2305\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(\n\u001b[32m   2306\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2307\u001b[39m     statement: Executable,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2313\u001b[39m     _add_event: Optional[Any] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2314\u001b[39m ) -> Result[Any]:\n\u001b[32m   2315\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Execute a SQL expression construct.\u001b[39;00m\n\u001b[32m   2316\u001b[39m \n\u001b[32m   2317\u001b[39m \u001b[33;03m    Returns a :class:`_engine.Result` object representing\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2363\u001b[39m \n\u001b[32m   2364\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2367\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2368\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2369\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbind_arguments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbind_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2370\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_parent_execute_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_parent_execute_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2371\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_add_event\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_add_event\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2372\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:2251\u001b[39m, in \u001b[36mSession._execute_internal\u001b[39m\u001b[34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event, _scalar_result)\u001b[39m\n\u001b[32m   2246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m conn.scalar(\n\u001b[32m   2247\u001b[39m         statement, params \u001b[38;5;129;01mor\u001b[39;00m {}, execution_options=execution_options\n\u001b[32m   2248\u001b[39m     )\n\u001b[32m   2250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compile_state_cls:\n\u001b[32m-> \u001b[39m\u001b[32m2251\u001b[39m     result: Result[Any] = \u001b[43mcompile_state_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43morm_execute_statement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbind_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2258\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2259\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2260\u001b[39m     result = conn.execute(\n\u001b[32m   2261\u001b[39m         statement, params \u001b[38;5;129;01mor\u001b[39;00m {}, execution_options=execution_options\n\u001b[32m   2262\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sqlalchemy\\orm\\context.py:306\u001b[39m, in \u001b[36mAbstractORMCompileState.orm_execute_statement\u001b[39m\u001b[34m(cls, session, statement, params, execution_options, bind_arguments, conn)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34morm_execute_statement\u001b[39m(\n\u001b[32m    298\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    304\u001b[39m     conn,\n\u001b[32m    305\u001b[39m ) -> Result:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     result = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.orm_setup_cursor_result(\n\u001b[32m    310\u001b[39m         session,\n\u001b[32m    311\u001b[39m         statement,\n\u001b[32m   (...)\u001b[39m\u001b[32m    315\u001b[39m         result,\n\u001b[32m    316\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1415\u001b[39m, in \u001b[36mConnection.execute\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1414\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1415\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1416\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1419\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:523\u001b[39m, in \u001b[36mClauseElement._execute_on_connection\u001b[39m\u001b[34m(self, connection, distilled_params, execution_options)\u001b[39m\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m    522\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    527\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1637\u001b[39m, in \u001b[36mConnection._execute_clauseelement\u001b[39m\u001b[34m(self, elem, distilled_parameters, execution_options)\u001b[39m\n\u001b[32m   1625\u001b[39m compiled_cache: Optional[CompiledCacheType] = execution_options.get(\n\u001b[32m   1626\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompiled_cache\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.engine._compiled_cache\n\u001b[32m   1627\u001b[39m )\n\u001b[32m   1629\u001b[39m compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(\n\u001b[32m   1630\u001b[39m     dialect=dialect,\n\u001b[32m   1631\u001b[39m     compiled_cache=compiled_cache,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1635\u001b[39m     linting=\u001b[38;5;28mself\u001b[39m.dialect.compiler_linting | compiler.WARN_LINTING,\n\u001b[32m   1636\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1637\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1638\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1639\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1640\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1645\u001b[39m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1649\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[32m   1650\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_execute(\n\u001b[32m   1651\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1652\u001b[39m         elem,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1656\u001b[39m         ret,\n\u001b[32m   1657\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1842\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1840\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exec_insertmany_context(dialect, context)\n\u001b[32m   1841\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[32m   1844\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1982\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1979\u001b[39m     result = context._setup_result_proxy()\n\u001b[32m   1981\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1982\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1983\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1984\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2354\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[39m\n\u001b[32m   2352\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2353\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2354\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc_info[\u001b[32m1\u001b[39m].with_traceback(exc_info[\u001b[32m2\u001b[39m])\n\u001b[32m   2355\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2356\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reentrant_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1963\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1961\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1963\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1964\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1965\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1967\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n\u001b[32m   1968\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_cursor_execute(\n\u001b[32m   1969\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1970\u001b[39m         cursor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1974\u001b[39m         context.executemany,\n\u001b[32m   1975\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:943\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\pymysql\\cursors.py:153\u001b[39m, in \u001b[36mCursor.execute\u001b[39m\u001b[34m(self, query, args)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    151\u001b[39m query = \u001b[38;5;28mself\u001b[39m.mogrify(query, args)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m._executed = query\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\pymysql\\cursors.py:322\u001b[39m, in \u001b[36mCursor._query\u001b[39m\u001b[34m(self, q)\u001b[39m\n\u001b[32m    320\u001b[39m conn = \u001b[38;5;28mself\u001b[39m._get_db()\n\u001b[32m    321\u001b[39m \u001b[38;5;28mself\u001b[39m._clear_result()\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[38;5;28mself\u001b[39m._do_get_result()\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rowcount\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\pymysql\\connections.py:562\u001b[39m, in \u001b[36mConnection.query\u001b[39m\u001b[34m(self, sql, unbuffered)\u001b[39m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    561\u001b[39m     sql = sql.encode(\u001b[38;5;28mself\u001b[39m.encoding, \u001b[33m\"\u001b[39m\u001b[33msurrogateescape\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCOMMAND\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCOM_QUERY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[38;5;28mself\u001b[39m._affected_rows = \u001b[38;5;28mself\u001b[39m._read_query_result(unbuffered=unbuffered)\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._affected_rows\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\pymysql\\connections.py:864\u001b[39m, in \u001b[36mConnection._execute_command\u001b[39m\u001b[34m(self, command, sql)\u001b[39m\n\u001b[32m    862\u001b[39m prelude = struct.pack(\u001b[33m\"\u001b[39m\u001b[33m<iB\u001b[39m\u001b[33m\"\u001b[39m, packet_size, command)\n\u001b[32m    863\u001b[39m packet = prelude + sql[: packet_size - \u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_write_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacket\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[32m    866\u001b[39m     dump_packet(packet)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\miniconda3\\Lib\\site-packages\\pymysql\\connections.py:806\u001b[39m, in \u001b[36mConnection._write_bytes\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    804\u001b[39m \u001b[38;5;28mself\u001b[39m._sock.settimeout(\u001b[38;5;28mself\u001b[39m._write_timeout)\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m806\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43msendall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    808\u001b[39m     \u001b[38;5;28mself\u001b[39m._force_close()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "datas = pd.date_range(start=\"2009-01-01\", end=\"2011-11-01\", freq=\"MS\")\n",
    "for data_inicio in tqdm(datas):\n",
    "    data_fim = pd.date_range(start=data_inicio, periods=1, freq=\"ME\")[0]\n",
    "\n",
    "    #treinando\n",
    "    model = OHERandomForestClassifier()\n",
    "    task = ClassificationTrainingTask () \n",
    "    run = Run(project = project, dataset = dataset,task = task,  model = model)\n",
    "    run.execute( task_parameters={'end_date':data_inicio})\n",
    "    run_dto = conversor.converter_object_to_dto(run)\n",
    "    run_repo = RunRepository(session=session)   \n",
    "    run_repo.save(run_dto)\n",
    "\n",
    "    #predi√ß√£o\n",
    "        \n",
    "    slices = [{'condition':\"addr_state == 'NY'\", 'description':'NY'},\n",
    "            {'condition':\"addr_state == 'CA'\", 'description':'CA'},\n",
    "            {'condition':\"addr_state == 'FL'\", 'description':'FL'},\n",
    "            {'condition':\"addr_state == 'TX'\", 'description':'TX'},\n",
    "            {'condition':\"addr_state == 'IL'\", 'description':'IL'}]\n",
    "\n",
    "    model.idModel =  run_dto.model.idModel\n",
    "    task = ClassificationPredictionTask () \n",
    "    run = Run(project = project,dataset = dataset, task = task,  model = model)\n",
    "    run.execute( task_parameters={'start_date':data_inicio,'end_date':data_fim, 'slices' :slices})\n",
    "\n",
    "    run_dto = conversor.converter_object_to_dto(run)\n",
    "    run_repo = RunRepository(session=session)\n",
    "    run_repo.save(run_dto)\n",
    "\n",
    "    #drift features, missing features, correlation, outliers\n",
    "    for task in [FeatureDriftTask (), FeatureMissingTask(),\\\n",
    "                  FeatureCorrelationTask(), OutlierDetectionTask() ]:\n",
    "        run = Run(project = project,dataset = dataset, task = task,  model = None)\n",
    "        run.execute( task_parameters={'end_reference_date':data_inicio,\n",
    "                                        'start_current_date':data_inicio,'end_current_date':data_fim})\n",
    "        run_dto = conversor.converter_object_to_dto(run)\n",
    "        run_repo = RunRepository(session=session)\n",
    "        run_repo.save(run_dto)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seoul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'SeoulBike'\n",
    "target_feature_name = 'rented_bike_count'\n",
    "name_space= project_name\n",
    "\n",
    "def process_raw_seoul_data():\n",
    "\n",
    "    def remove_parentheses_content(text):\n",
    "        return re.sub(r'\\([^)]*\\)', '', text)\n",
    "\n",
    "    df = pd.read_csv('data//SeoulBikeData.csv', encoding='latin1')\n",
    "    df.columns = [remove_parentheses_content(i.lower()).strip().replace(' ','_') for i in df.columns]\n",
    "    df['timestamp'] = df['date'].map(lambda x : datetime.strptime(x,  \"%d/%m/%Y\"))\n",
    "    df = df.drop(columns = 'date')\n",
    "    df['timestamp'] = df['timestamp'] + pd.to_timedelta(df['hour'], unit='h')\n",
    "    df_melt = df.melt(id_vars = ['timestamp'], value_vars = df.drop(columns = 'timestamp').columns)\n",
    "    df_melt['idEntity'] = '1'\n",
    "    df_melt['type'] = df_melt['value'].map(lambda x : type(x).__name__)\n",
    "    df_melt.rename(columns ={'variable':'name'}, inplace=True)\n",
    "    return df_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = Dataset(name = project_name)\n",
    "item_exists, dataset_dto = conversor.get_if_exists(dataset)\n",
    "\n",
    "if not(item_exists):\n",
    "    df = process_raw_seoul_data()\n",
    "\n",
    "    dataset_dto = DatasetDTO(name = project_name ) \n",
    "    lst_features= df['name'].drop_duplicates().to_list()\n",
    "    dataset_dto.process_feature_list(lst_features= lst_features, name_space=name_space)\n",
    "    dataset_repo.save(dataset_dto)\n",
    "    item_exists, dataset_dto = conversor.get_if_exists(dataset)\n",
    "    dataset_dto.save_data_mongo(mongo_db ,df = df)\n",
    "\n",
    "dataset_dto.load_data_from_mongo(mongo_db)\n",
    "dataset = dataset_dto.dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetFeature = Feature(name = target_feature_name, nameSpace = FeatureNameSpace(name = name_space))\n",
    "project = Project(name  = project_name, projectType = ProjectType(name = 'Regression'), targetFeature = targetFeature)\n",
    "\n",
    "item_exists,project_dto = conversor.get_if_exists(project)\n",
    "\n",
    "if not(item_exists):\n",
    "\ttargetFeature = dataset_dto.get_feature_by_name(name = target_feature_name)\n",
    "\tproject_dto =ProjectDTO(name  = project_name, projectType = ProjectTypeDTO(name = 'Regression'), targetFeature = targetFeature)\n",
    "\tProjectRepository(session=session).save(project_dto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a5da2717844344915f0532b36c7494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datas = pd.date_range(start=\"2018-01-01\", end=\"2018-11-30\", freq=\"MS\")  \n",
    "for data_inicio in tqdm(datas):\n",
    "    data_fim = pd.date_range(start=data_inicio, periods=1, freq=\"ME\")[0]\n",
    "\n",
    "    #treinando\n",
    "    model = OHEDecisionTreeRegressor()\n",
    "    task = RegressionTrainingTask () \n",
    "    run = Run(project = project, dataset = dataset, task = task,  model = model)\n",
    "    run.execute( task_parameters={'end_date':data_inicio})\n",
    "    run_dto = conversor.converter_object_to_dto(run)\n",
    "    run_repo = RunRepository(session=session)   \n",
    "    run_repo.save(run_dto)\n",
    "\n",
    "    slices = [{'condition':\"hour >= 9 and hour <= 18\", 'description':'business hours'},\n",
    "            {'condition':\"hour < 9 or hour > 18\", 'description':'not business hours'}]\n",
    "\n",
    "    #predi√ß√£o\n",
    "    model.idModel =  run_dto.model.idModel\n",
    "    task = RegressionPredictionTask () \n",
    "    run = Run(project = project, dataset = dataset, task = task,  model = model)\n",
    "    run.execute( task_parameters={'start_date':data_inicio,'end_date':data_fim, 'slices':slices})\n",
    "    run_dto = conversor.converter_object_to_dto(run)\n",
    "    run_repo = RunRepository(session=session)\n",
    "    run_repo.save(run_dto)\n",
    "\n",
    "    #drift features, missing features, correlation, outliers\n",
    "    for task in [FeatureDriftTask (), FeatureMissingTask(),\\\n",
    "                  FeatureCorrelationTask(), OutlierDetectionTask() ]:\n",
    "        run = Run(project = project, dataset = dataset,task = task,  model = None)\n",
    "        run.execute( task_parameters={'end_reference_date':data_inicio,\n",
    "                                        'start_current_date':data_inicio,'end_current_date':data_fim})\n",
    "        run_dto = conversor.converter_object_to_dto(run)\n",
    "        run_repo = RunRepository(session=session)\n",
    "        run_repo.save(run_dto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime Recidivism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "project_name = 'CrimeRecidivismPrediction'\n",
    "target_feature_name = 'two_year_recid'\n",
    "name_space= project_name\n",
    "\n",
    "def process_raw_compass_data():\n",
    "    url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "    df = pd.read_csv(url, parse_dates=[\"screening_date\"])\n",
    "\n",
    "    # 2. Filter the data (as done by ProPublica)\n",
    "    df = df[\n",
    "        (df[\"days_b_screening_arrest\"] <= 30) &\n",
    "        (df[\"days_b_screening_arrest\"] >= -30) &\n",
    "        (df[\"is_recid\"] != -1) &\n",
    "        (df[\"c_charge_degree\"] != \"O\") &\n",
    "        (df[\"score_text\"] != \"N/A\")\n",
    "    ].copy()\n",
    "\n",
    "    replace_dict = {'Native American':'others','Asian':'others'}\n",
    "    df['race'] = df['race'].replace(replace_dict)\n",
    "\n",
    "    # 3. Rename columns to be clearer\n",
    "    df = df.rename(columns={\n",
    "        \"age\": \"age\",\n",
    "        \"sex\": \"gender\",\n",
    "        \"race\": \"ethnicity\",\n",
    "        \"juv_fel_count\": \"juvenile_felonies\",\n",
    "        \"juv_misd_count\": \"juvenile_misdemeanors\",\n",
    "        \"juv_other_count\": \"juvenile_other_offenses\",\n",
    "        \"priors_count\": \"prior_offenses\",\n",
    "        \"c_charge_degree\": \"charge_degree\",\n",
    "        \"c_charge_desc\": \"charge_description\",\n",
    "        'screening_date':'timestamp',\n",
    "        'id':'idEntity'\n",
    "    })\n",
    "\n",
    "    # 4. Replace values in charge_degree for clarity\n",
    "    df[\"charge_degree\"] = df[\"charge_degree\"].replace({\n",
    "        \"F\": \"Felony\",\n",
    "        \"M\": \"Misdemeanor\"\n",
    "    })\n",
    "\n",
    "    file_path = 'data//compass_crime_desc_map.json'\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        crime_dict = json.load(file)\n",
    "\n",
    "    df['charge_category'] = df['charge_description'].replace(crime_dict)\n",
    "    df['charge_category'] = df['charge_category'] .fillna('Other')\n",
    "\n",
    "    # 5. Define features and target\n",
    "    feature_columns = [\n",
    "        \"age\",\n",
    "        \"gender\",\n",
    "        \"ethnicity\",\n",
    "        \"juvenile_felonies\",\n",
    "        \"juvenile_misdemeanors\",\n",
    "        \"juvenile_other_offenses\",\n",
    "        \"prior_offenses\",\n",
    "        \"charge_degree\",\n",
    "        \"charge_category\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    target_column = \"two_year_recid\"\n",
    "\n",
    "    # 6. Final dataset\n",
    "    df = df[['idEntity','timestamp']+feature_columns + [target_column]].copy()\n",
    "\n",
    "    # 7. Preview\n",
    "    df['idEntity'] = df['idEntity'].astype('string') \n",
    "\n",
    "    df_melt = df.melt(id_vars = ['timestamp','idEntity'], value_vars = df.drop(columns = 'timestamp').columns)\n",
    "    df_melt['type'] = df_melt['value'].map(lambda x : type(x).__name__)\n",
    "    df_melt.rename(columns ={'variable':'name'}, inplace=True)\n",
    "    return df_melt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = Dataset(name = project_name)\n",
    "item_exists, dataset_dto = conversor.get_if_exists(dataset)\n",
    "\n",
    "if not(item_exists):\n",
    "    df = process_raw_compass_data()\n",
    "\n",
    "    dataset_dto = DatasetDTO(name = project_name ) \n",
    "    lst_features= df['name'].drop_duplicates().to_list()\n",
    "    dataset_dto.process_feature_list(lst_features= lst_features, name_space=name_space)\n",
    "    dataset_repo.save(dataset_dto)\n",
    "    item_exists, dataset_dto = conversor.get_if_exists(dataset)\n",
    "    dataset_dto.save_data_mongo(mongo_db ,df = df)\n",
    "\n",
    "dataset_dto.load_data_from_mongo(mongo_db)\n",
    "dataset = dataset_dto.dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetFeature = Feature(name = target_feature_name, nameSpace = FeatureNameSpace(name = name_space))\n",
    "project = Project(name  = project_name, projectType = ProjectType(name = 'Classification'), targetFeature = targetFeature)\n",
    "\n",
    "item_exists,project_dto = conversor.get_if_exists(project)\n",
    "\n",
    "if not(item_exists):\n",
    "\ttargetFeature = dataset_dto.get_feature_by_name(name = target_feature_name)\n",
    "\tproject_dto =ProjectDTO(name  = project_name, projectType = ProjectTypeDTO(name = 'Classification'), targetFeature = targetFeature)\n",
    "\tProjectRepository(session=session).save(project_dto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb100c713f94561b6225037e07fe8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|=================== | 556/576 [00:15<00:00]       c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\Lift10MeasureProcedure.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  top_k_rate = positives_top_k / cutoff\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\Lift20MeasureProcedure.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  top_k_rate = positives_top_k / cutoff\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\Lift10MeasureProcedure.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  top_k_rate = positives_top_k / cutoff\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Documents\\EvaluationStoreProject\\Aplica√ß√£o\\Core\\Relations\\MeasureProcedures\\KSMeasureProcedure.py:12: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_value = ks_2samp(pos_scores, neg_scores)\n"
     ]
    }
   ],
   "source": [
    "datas = pd.date_range(start=\"2013-09-01\", end=\"2014-06-01\", freq=\"MS\")[:24]\n",
    "for data_inicio in tqdm(datas):\n",
    "    data_fim = pd.date_range(start=data_inicio, periods=1, freq=\"ME\")[0]\n",
    "\n",
    "    #treinando\n",
    "    model = OHERandomForestClassifier()\n",
    "    task = ClassificationTrainingTask () \n",
    "    run = Run(project = project,dataset = dataset, task = task,  model = model)\n",
    "    run.execute( task_parameters={'end_date':data_inicio})\n",
    "    run_dto = conversor.converter_object_to_dto(run)\n",
    "    run_repo = RunRepository(session=session)   \n",
    "    run_repo.save(run_dto)\n",
    "\n",
    "    #predi√ß√£o\n",
    "        \n",
    "    slices = [{'condition':\"ethnicity == 'African-American'\", 'description':'African-American'},\n",
    "            {'condition':\"ethnicity == 'Caucasian'\", 'description':'Caucasian'},\n",
    "            {'condition':\"ethnicity == 'Hispanic'\", 'description':'Hispanic'},\n",
    "            {'condition':\"gender == 'Male'\", 'description':'Male'},\n",
    "            {'condition':\"gender == 'Female'\", 'description':'Female'}]\n",
    "\n",
    "    model.idModel =  run_dto.model.idModel\n",
    "    task = ClassificationPredictionTask () \n",
    "    run = Run(project = project, dataset = dataset,task = task,  model = model)\n",
    "    run.execute( task_parameters={'start_date':data_inicio,'end_date':data_fim, 'slices' :slices})\n",
    "\n",
    "    run_dto = conversor.converter_object_to_dto(run)\n",
    "    run_repo = RunRepository(session=session)\n",
    "    run_repo.save(run_dto)\n",
    "\n",
    "    #drift features, missing features, correlation, outliers\n",
    "    for task in [FeatureDriftTask (), FeatureMissingTask(),\\\n",
    "                  FeatureCorrelationTask(), OutlierDetectionTask() ]:\n",
    "        run = Run(project = project,dataset = dataset, task = task,  model = None)\n",
    "        run.execute( task_parameters={'end_reference_date':data_inicio,\n",
    "                                        'start_current_date':data_inicio,'end_current_date':data_fim})\n",
    "        run_dto = conversor.converter_object_to_dto(run)\n",
    "        run_repo = RunRepository(session=session)\n",
    "        run_repo.save(run_dto)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
